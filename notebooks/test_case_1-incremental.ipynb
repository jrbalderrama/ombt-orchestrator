{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Post-mortem analysis\n",
    "\n",
    "Referenced test plan: https://docs.openstack.org/performance-docs/latest/test_plans/massively_distribute_rpc/plan.html\n",
    "\n",
    "Test considered: Test Case 1 (One single large target)\n",
    "\n",
    "## System under test\n",
    "\n",
    "\n",
    "```\n",
    "Client 1---------+      +----------------------+     +-----> Server 1\n",
    "                 |      |                      |     |\n",
    "                 +----> |  RabbitMQ            | ----+-----> Server 2\n",
    "Client 2--------------> |  Standalone          |     |\n",
    "                 +----> |                      |     |\n",
    "...              |      |                      |     |\n",
    "                 |      +----------------------+     +------> Server n\n",
    "Client n---------+              |                             /\n",
    "  \\                                                         /\n",
    "    \\                           |                         / \n",
    "      \\  --  --  --  --  -- Monitoring --  --  --  --  --\n",
    "```\n",
    "\n",
    "Direct links : \n",
    "\n",
    "* [Hardware](#Hardware)\n",
    "* [Software](#Software)\n",
    "* Get Ombt stats\n",
    "    * [Ombt-statistics](#Ombt-statistics) (general stats: message_rate, latency, ...)\n",
    "    * [Graphs](#Ombt-statistics-graphs)\n",
    "* Get Influxdb stats\n",
    "    * [Influxdb-Metrics](#Influxdb-Metrics) (can take time, use if system metrics are needed, ...)\n",
    "    * [Graphs](#Graphs) of system metrics\n",
    "        * [RPC-CALLs-metrics](#RPC-CALLs-metrics)\n",
    "        * [RPC-CASTs-metrics](#RPC-CASTs-metrics)\n",
    "        \n",
    "# Hardware\n",
    "\n",
    "Platform: [Grid'5000](https://www.grid5000.fr/mediawiki/index.php/Grid5000:Home)\n",
    "\n",
    "* Bus: One dedicated physical machine\n",
    "    * 1x: https://www.grid5000.fr/mediawiki/index.php/Rennes:Hardware#Dell_Poweredge_R630_.28parasilo.29\n",
    "\n",
    "* Clients: 125 physical machines.\n",
    "    * 40x: https://www.grid5000.fr/mediawiki/index.php/Rennes:Hardware#Dell_Poweredge_R630_.28paravance.29\n",
    "\n",
    "* servers: 30 + 8 physical machines\n",
    "    * 20x: https://www.grid5000.fr/mediawiki/index.php/Rennes:Hardware#Dell_Poweredge_R630_.28paravance.29\n",
    " \n",
    " \n",
    "# Software\n",
    "\n",
    "* Linux distribution\n",
    "\n",
    "```\n",
    "Distributor ID: Debian\n",
    "Description:    Debian GNU/Linux 9.3 (stretch)\n",
    "Release:        9.3\n",
    "Codename:       stretch\n",
    "```\n",
    "\n",
    "* RabbitMQ\n",
    "\n",
    "TODO\n",
    "\n",
    "* Ombt versions\n",
    "\n",
    "TODO\n",
    "\n",
    "Built from [6ac8255](https://github.com/kgiusti/ombt/commit/6ac8255896c794254bad080fc89dcbb1d9e0cb38)\n",
    "    * oslo.messaging==5.35.0\n",
    "    * pyngus==2.2.2\n",
    "    * python-qpid-proton==0.19.0\n",
    "    \n",
    "\n",
    "# Data\n",
    "\n",
    "This notebook was run with: http://enos.irisa.fr/ombt-orchestrator/test_case_1_rabbitmq/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get ombt statistics\n",
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the env dir of the experimental campaign\n",
    "RESULT_PATH = \"./test_case_1-incremental-it-1/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserting some ombt code (this could be removed when used as a library)\n",
    "# This is used to recover the global stats from the per-agent stats\n",
    "# Per agent stats are outputed from the controller in a dedicated.\n",
    "\n",
    "import math\n",
    "\n",
    "class Stats(object):\n",
    "    \"\"\"Manage a single statistic\"\"\"\n",
    "    def __init__(self, min=None, max=None, total=0, count=0, sum_of_squares=0, distribution=None):\n",
    "        self.min = min\n",
    "        self.max = max\n",
    "        self.total = total\n",
    "        self.count = count\n",
    "        self.sum_of_squares = sum_of_squares\n",
    "        # distribution of values grouped by powers of 10\n",
    "        self.distribution = distribution or dict()\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, values):\n",
    "        if 'distribution' in values:\n",
    "            # hack alert!\n",
    "            # when a Stats is passed via an RPC call it appears as if the\n",
    "            # distribution map's keys are converted from int to str.\n",
    "            # Fix that by re-indexing the distribution map:\n",
    "            new_dict = dict()\n",
    "            old_dict = values['distribution']\n",
    "            for k in old_dict.keys():\n",
    "                new_dict[int(k)] = old_dict[k];\n",
    "            values['distribution'] = new_dict\n",
    "        return Stats(**values)\n",
    "\n",
    "    def to_dict(self):\n",
    "        new_dict = dict()\n",
    "        for a in [\"min\", \"max\", \"total\", \"count\", \"sum_of_squares\"]:\n",
    "            new_dict[a] = getattr(self, a)\n",
    "        new_dict[\"distribution\"] = self.distribution.copy()\n",
    "        return new_dict\n",
    "\n",
    "    def update(self, value):\n",
    "        self.total += value\n",
    "        self.count += 1\n",
    "        self.sum_of_squares += value**2\n",
    "        self.min = min(self.min, value) if self.min else value\n",
    "        self.max = max(self.max, value) if self.max else value\n",
    "        log = int(math.log10(value)) if value >= 1.0 else 0\n",
    "        base = 10**log\n",
    "        index = int(value/base)  # 0..9\n",
    "        if log not in self.distribution:\n",
    "            self.distribution[log] = [0 for i in range(10)]\n",
    "        self.distribution[log][index] += 1\n",
    "\n",
    "    def reset(self):\n",
    "        self.__init__()\n",
    "\n",
    "    def average(self):\n",
    "        return (self.total / float(self.count)) if self.count else 0\n",
    "\n",
    "    def std_deviation(self):\n",
    "        return math.sqrt((self.sum_of_squares / float(self.count))\n",
    "                         - (self.average() ** 2)) if self.count else -1\n",
    "\n",
    "    def merge(self, stats):\n",
    "        if stats.min is not None and self.min is not None:\n",
    "            self.min = min(self.min, stats.min)\n",
    "        else:\n",
    "            self.min = self.min or stats.min\n",
    "        if stats.max is not None and self.max is not None:\n",
    "            self.max = max(self.max, stats.max)\n",
    "        else:\n",
    "            self.max = self.max or stats.max\n",
    "\n",
    "        self.total += stats.total\n",
    "        self.count += stats.count\n",
    "        self.sum_of_squares += stats.sum_of_squares\n",
    "        for k in stats.distribution.keys():\n",
    "            if k in self.distribution:\n",
    "                self.distribution[k] = [z for z in map(lambda a, b: a + b,\n",
    "                                                       stats.distribution[k],\n",
    "                                                       self.distribution[k])]\n",
    "            else:\n",
    "                self.distribution[k] = stats.distribution[k]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"min=%i, max=%i, avg=%f, std-dev=%f\" % (self.min, self.max,\n",
    "                                                       self.average(),\n",
    "                                                       self.std_deviation())\n",
    "\n",
    "    def print_distribution(self):\n",
    "        keys = list(self.distribution.keys())\n",
    "        keys.sort()\n",
    "        for order in keys:\n",
    "            row = self.distribution[order]\n",
    "            # order=0, index=0 is special case as it is < 1.0, for all orders >\n",
    "            # 0, index 0 is ignored since everthing < 10^order is accounted for\n",
    "            # in index 9 of the (order - 1) row\n",
    "            index = 0 if order == 0 else 1\n",
    "            while index < len(row):\n",
    "                print(\"[%d..<%d):  %d\" %\n",
    "                      ((10 ** int(order)) * index,\n",
    "                       (10 ** int(order)) * (index + 1),\n",
    "                       row[index]))\n",
    "                index += 1\n",
    "\n",
    "class TestResults(object):\n",
    "    \"\"\"Client results of a test run.\n",
    "    \"\"\"\n",
    "    def __init__(self, start_time=None, stop_time=None, latency=None,\n",
    "                 msgs_ok=0, msgs_fail=0, errors=None):\n",
    "        super(TestResults, self).__init__()\n",
    "        self.start_time = start_time\n",
    "        self.stop_time = stop_time\n",
    "        self.latency = latency or Stats()\n",
    "        self.msgs_ok = msgs_ok  # count of successful msg transfers\n",
    "        self.msgs_fail = msgs_fail  # count of failed msg transfers\n",
    "        self.errors = errors or dict()  # error msgs and counts\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, values):\n",
    "        if 'latency' in values:\n",
    "            values['latency'] = Stats.from_dict(values['latency'])\n",
    "        if 'errors' in values:\n",
    "            values['errors'] = values['errors'].copy()\n",
    "        return TestResults(**values)\n",
    "\n",
    "    def to_dict(self):\n",
    "        new_dict = dict()\n",
    "        for a in ['start_time', 'stop_time', 'msgs_ok', 'msgs_fail']:\n",
    "            new_dict[a] = getattr(self, a)\n",
    "        new_dict['latency'] = self.latency.to_dict()\n",
    "        new_dict['errors'] = self.errors.copy()\n",
    "        return new_dict\n",
    "\n",
    "    def error(self, reason):\n",
    "        key = str(reason)\n",
    "        self.errors[key] = self.errors.get(key, 0) + 1\n",
    "\n",
    "    def reset(self):\n",
    "        self.__init__()\n",
    "\n",
    "    def merge(self, results):\n",
    "        self.start_time = (min(self.start_time, results.start_time)\n",
    "                           if self.start_time and results.start_time\n",
    "                           else (self.start_time or results.start_time))\n",
    "        self.stop_time = (max(self.stop_time, results.stop_time)\n",
    "                              if self.stop_time and results.stop_time\n",
    "                          else (self.stop_time or results.stop_time))\n",
    "        self.msgs_ok += results.msgs_ok\n",
    "        self.msgs_fail += results.msgs_fail\n",
    "        self.latency.merge(results.latency)\n",
    "        for err in results.errors:\n",
    "            self.errors[err] = self.errors.get(err, 0) + results.errors[err]\n",
    "\n",
    "    def print_results(self):\n",
    "        if self.msgs_fail:\n",
    "            print(\"Error: %d message transfers failed\"\n",
    "                  % self.msgs_fail)\n",
    "        if self.errors:\n",
    "            print(\"Error: errors detected:\")\n",
    "            for err in self.errors:\n",
    "                print(\"  '%s' (occurred %d times)\" % (err, self.errors[err]))\n",
    "\n",
    "        total = self.msgs_ok + self.msgs_fail\n",
    "        print(\"Total Messages: %d\" % total)\n",
    "\n",
    "        delta_time = self.stop_time - self.start_time\n",
    "        print(\"Test Interval: %f - %f (%f secs)\" % (self.start_time,\n",
    "                                                    self.stop_time,\n",
    "                                                    delta_time))\n",
    "\n",
    "        if delta_time > 0.0:\n",
    "            print(\"Aggregate throughput: %f msgs/sec\" % (float(total)/delta_time))\n",
    "\n",
    "        latency = self.latency\n",
    "        if latency.count:\n",
    "            print(\"Latency %d samples (msecs): Average %f StdDev %f\"\n",
    "                  \" Min %f Max %f\"\n",
    "                  % (latency.count,\n",
    "                     latency.average(), latency.std_deviation(),\n",
    "                     latency.min, latency.max))\n",
    "            print(\"Latency Distribution: \")\n",
    "            latency.print_distribution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some util functions\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import statistics\n",
    "from os import path\n",
    "\n",
    "def load_stats(param):\n",
    "    \"\"\"Loads the stats for the controller output file.\"\"\"\n",
    "    try:\n",
    "        all_controller = path.join(RESULT_PATH, param[\"backup_dir\"], \"*controller*.log\")\n",
    "        all_controller_docker = path.join(RESULT_PATH, param[\"backup_dir\"], \"*controller*_docker.log\")\n",
    "        # beware of the files _docker.log that would also match\n",
    "        # and contains the global stats in a human readable format.\n",
    "        allfiles = glob.glob(all_controller)\n",
    "        alldocker = glob.glob(all_controller_docker)\n",
    "        controller_logs = set(allfiles) - set(alldocker)\n",
    "\n",
    "        stats_clients = {}\n",
    "        stats_servers = {}\n",
    "        # We build aggregates on all shards\n",
    "        for controller_log in controller_logs:\n",
    "            with open(controller_log) as f:\n",
    "                a = f.readlines()\n",
    "                # NOTE make sure rpc client|server names are different accros shards\n",
    "                stats_clients.update(json.loads(a[0]))\n",
    "                stats_servers.update(json.loads(a[1]))\n",
    "        return stats_clients, stats_servers\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def build_agg_results(results):\n",
    "    agg = TestResults()\n",
    "    for result in results:\n",
    "        result[\"latency\"] = Stats(**result[\"latency\"])\n",
    "        agg.merge(TestResults(**result))\n",
    "        \n",
    "    duration = agg.stop_time - agg.start_time\n",
    "    total = agg.msgs_ok + agg.msgs_fail\n",
    "    rate = float(total)/duration\n",
    "    result = agg.to_dict()\n",
    "    result[\"rate\"] = rate\n",
    "    result[\"latency_avg\"] = agg.latency.average()\n",
    "    result[\"latency_stdev\"] = agg.latency.std_deviation()\n",
    "    return result\n",
    "\n",
    "def build_msgs_stats(results, msg_type):\n",
    "    # NOTE(msimonin): we don't expect a TestResult here\n",
    "    msgs = [r[msg_type] for r in results]\n",
    "    return {\n",
    "        \"mean\": statistics.mean(msgs),\n",
    "        #\"stdev\": statistics.stdev(msgs),\n",
    "        \"min\": min(msgs),\n",
    "        \"max\": max(msgs)\n",
    "    }\n",
    "\n",
    "def augment(mydict, myparams, in_key, out_key=None):\n",
    "    out_key = out_key or in_key\n",
    "    mydict.update({out_key: [p[in_key] for p in myparams]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the params from the params file\n",
    "\n",
    "params = []\n",
    "with open(path.join(RESULT_PATH, \"params.json\")) as f:\n",
    "    params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wich parameters to deal with\n",
    "# this allows to test for a subset only\n",
    "\n",
    "PARAMS = []\n",
    "for param in params:\n",
    "    stats = load_stats(param)\n",
    "    if not stats:\n",
    "        continue\n",
    "    clients, servers = stats\n",
    "    # what has been seen by ombt\n",
    "    param[\"_ombt_clients\"] = len(clients.values())\n",
    "    param[\"_ombt_servers\"] = len(servers.values())\n",
    "    param[\"_ombt_msgs_sent_ok\"] = build_msgs_stats(clients.values(), \"msgs_ok\")\n",
    "    param[\"_ombt_msgs_received_ok\"] = build_msgs_stats(servers.values(), \"msgs_ok\")\n",
    "    param[\"_ombt_msgs_sent_fail\"] = build_msgs_stats(clients.values(), \"msgs_fail\")\n",
    "    param[\"_ombt_msgs_received_fail\"] = build_msgs_stats(servers.values(), \"msgs_fail\")\n",
    "    #param[\"_raw_servers_test_result\"] = servers\n",
    "    #param[\"_raw_clients_test_result\"] = clients\n",
    "    param[\"_agg_servers\"] = build_agg_results(servers.values())\n",
    "    param[\"_agg_clients\"] = build_agg_results(clients.values())\n",
    "    PARAMS.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"params_calculated.json\", \"w\") as f:\n",
    "    json.dump(PARAMS, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting some stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction = {}\n",
    "to_extract = [\"_ombt_clients\", \"_ombt_servers\",  \"call_type\", \"driver\", \"iteration_id\"]\n",
    "for e in to_extract:\n",
    "    augment(extraction, PARAMS, e)\n",
    "\n",
    "# Rate server side\n",
    "extraction.update({\n",
    "    \"server_rate\": [p[\"_agg_servers\"][\"rate\"] for p in PARAMS]\n",
    "})\n",
    "\n",
    "# Number of message processed correctly by all the servers\n",
    "extraction.update({\n",
    "    \"server_ok\": [p[\"_agg_servers\"][\"msgs_ok\"] for p in PARAMS]\n",
    "})\n",
    "\n",
    "# Number of message processed with a failure by all the servers\n",
    "extraction.update({\n",
    "    \"server_fail\": [p[\"_agg_servers\"][\"msgs_fail\"] for p in PARAMS]\n",
    "})\n",
    "\n",
    "# Average latency server side\n",
    "extraction.update({\n",
    "    \"server_latency_avg\": [p[\"_agg_servers\"][\"latency_avg\"] for p in PARAMS]\n",
    "})\n",
    "\n",
    "# Stddev latency server side\n",
    "extraction.update({\n",
    "    \"server_latency_stdev\": [p[\"_agg_servers\"][\"latency_stdev\"] for p in PARAMS]\n",
    "})\n",
    "\n",
    "# Average latency client side\n",
    "extraction.update({\n",
    "    \"client_latency_avg\": [p[\"_agg_clients\"][\"latency_avg\"] for p in PARAMS]\n",
    "})\n",
    "\n",
    "# Stddev latency client side\n",
    "extraction.update({\n",
    "    \"client_latency_stdev\": [p[\"_agg_clients\"][\"latency_stdev\"] for p in PARAMS]\n",
    "})\n",
    "\n",
    "# Rate server side\n",
    "extraction.update({\n",
    "    \"client_rate\": [p[\"_agg_clients\"][\"rate\"] for p in PARAMS]\n",
    "})\n",
    "\n",
    "# Number of message processed correctly by all the clients\n",
    "extraction.update({\n",
    "    \"client_ok\": [p[\"_agg_clients\"][\"msgs_ok\"] for p in PARAMS]\n",
    "})\n",
    "\n",
    "# Number of message processed with a failure by all the servers\n",
    "extraction.update({\n",
    "    \"client_fail\": [p[\"_agg_clients\"][\"msgs_fail\"] for p in PARAMS]\n",
    "})\n",
    "\n",
    "# Get a sense of what is happening on each client/server\n",
    "# min, max, avg of the number of message processed correctly by the clients\n",
    "extraction.update({\n",
    "    \"per_client_ok\": [p[\"_ombt_msgs_sent_ok\"] for p in PARAMS]\n",
    "})\n",
    "\n",
    "# min, max, avg of the number of message processed with a failure by the clients\n",
    "extraction.update({\n",
    "    \"per_client_fail\": [p[\"_ombt_msgs_sent_fail\"] for p in PARAMS]\n",
    "})\n",
    "\n",
    "# min, max, avg of the number of message processed correctly the servers\n",
    "extraction.update({\n",
    "    \"per_server_ok\": [p[\"_ombt_msgs_received_ok\"] for p in PARAMS]\n",
    "})\n",
    "\n",
    "# min, max, avg of the number of message processed with a failure by the servers\n",
    "extraction.update({\n",
    "    \"per_server_fail\": [p[\"_ombt_msgs_received_fail\"] for p in PARAMS]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ombt statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from IPython.display import display\n",
    "\n",
    "df = pandas.DataFrame(extraction)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ombt statistics graphs\n",
    "\n",
    "## Latency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import operator\n",
    "\n",
    "\n",
    "def plot_latency_dist(params, client_server, index):\n",
    "    \"\"\"\n",
    "    Draw the (aggregated) latency distribution \n",
    "    For casts we take the server latency\n",
    "    For calls we take the client latency\n",
    "    \"\"\"\n",
    "    agent = \"_agg_clients\" if params[index][\"call_type\"] == \"rpc-call\" else \"_agg_servers\"\n",
    "    distribution = params[index][agent][\"latency\"][\"distribution\"]\n",
    "    x = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    max_pw = 0\n",
    "    for p, numbers in distribution.items():\n",
    "        pw = int(p)\n",
    "        x.extend([math.log(x * 10 ** pw, 10)  for x in range(1, 11)])\n",
    "        labels.extend([10 ** pw] + 9 * [\"\"])\n",
    "        data.extend(numbers)\n",
    "        max_pw = max(pw, max_pw)\n",
    "        plt.bar(x, data, tick_label=labels, align='edge', edgecolor='black', width=-0.01)\n",
    "        # TODO fix the title\n",
    "        plt.title(\"%s - %s\" %( index + 1, params[index][\"call_type\"]))\n",
    "    \n",
    "PARAMS = sorted(PARAMS, key=operator.itemgetter('driver', 'call_type', 'nbr_clients'))\n",
    "# groups = [list(g) for _, g in itertools.groupby(PARAMS, lambda x: x['call_type'])]\n",
    "# print(len(groups))\n",
    "#print(len(groups[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for iteration in range(len(PARAMS)):\n",
    "    plot_latency_dist(PARAMS, \"server\", iteration)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric vs clients metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMS = sorted(PARAMS, key=operator.itemgetter('driver', 'call_type', 'nbr_clients'))\n",
    "#groups = [list(g) for _, g in itertools.groupby(PARAMS, lambda x: x['driver'])]\n",
    "#groups = [list(itertools.accumulate(iteration['nbr_servers'] for iteration in g)) for g in groups]\n",
    "drivers = df.driver.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_metric_vs_iteration(df, drivers, call_type, metric, yerr=None):\n",
    "    ax = None\n",
    "    for driver in drivers:\n",
    "        extract = df[(df.call_type == call_type) & (df.driver == driver)]\n",
    "        kwargs = {\"y\": metric, \"use_index\": False}                        \n",
    "        if yerr:\n",
    "            kwargs.update({\"yerr\": yerr})\n",
    "        if ax:         \n",
    "            kwargs.update({\"ax\": ax})\n",
    "        ax = extract.plot(**kwargs)\n",
    "            \n",
    "    #ax.set_xticklabels(extract._ombt_servers)\n",
    "    ax.legend(drivers)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metric_vs_iteration(df, drivers, \"rpc-call\", \"client_latency_avg\")\n",
    "draw_metric_vs_iteration(df, drivers, \"rpc-cast\", \"server_latency_avg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recovering metrics from influxdb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from influxdb import InfluxDBClient\n",
    "from influxdb.exceptions import InfluxDBServerError\n",
    "from requests import exceptions \n",
    "\n",
    "def wait_influx_to_get_ready(debug=False, log=False):\n",
    "    influxdb = InfluxDBClient(database=database, timeout=600)\n",
    "    if debug:\n",
    "        print('Connecting to InfluxDB ', end='', flush=True)\n",
    "    while True:\n",
    "        try:\n",
    "            version = influxdb.ping()                        \n",
    "            if debug:\n",
    "                print(' DONE')\n",
    "            if log:\n",
    "                print(version)\n",
    "                print(influxdb.get_list_database())\n",
    "            break\n",
    "            \n",
    "        except (InfluxDBServerError,\n",
    "                exceptions.HTTPError,\n",
    "                exceptions.ConnectionError,\n",
    "                exceptions.Timeout,\n",
    "                exceptions.RequestException) as error:            \n",
    "            if debug:\n",
    "                print('.', end='', flush=True)\n",
    "            time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "from influxdb import DataFrameClient\n",
    "\n",
    "client = docker.from_env()\n",
    "for container in client.containers.list():\n",
    "    container.stop()\n",
    "    container.remove(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import tarfile\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "import tqdm\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "tqdm.monitor_interval = 0\n",
    "\n",
    "# NOTE: depending on the version of ombt-orchestrator the \n",
    "# database may vary (telegraf or ombt-orchestrator)\n",
    "database = \"ombt-orchestrator\"\n",
    "\n",
    "#container_name=~/^router/\n",
    "# Assumption : there is at least a group.\n",
    "\n",
    "epoch = \"30\"\n",
    "\n",
    "# router metrics\n",
    "usage_mem_bus = \"SELECT mean(usage) FROM docker_container_mem WHERE container_name=~/^router/ and time>='%s' AND time<='%s' GROUP BY container_name, time({}s)\".format(epoch)\n",
    "usage_cpu_percent_bus = \"SELECT mean(usage_percent) FROM docker_container_cpu WHERE container_name=~/^router/ and time>='%s' AND time<='%s' GROUP BY container_name, time({}s)\".format(epoch)\n",
    "# This will work for rabbitmq or qdr\n",
    "tcp_established_bus = \"SELECT mean(tcp_established) FROM netstat WHERE role='bus' and time>='%s' AND time<='%s' GROUP BY host, time({}s)\".format(epoch)\n",
    "\n",
    "# rabbit metrics\n",
    "usage_mem_rabbit = \"SELECT mean(usage) FROM docker_container_mem WHERE container_name=~/^rabbit/ and time>='%s' AND time<='%s' GROUP BY container_name, time({}s)\".format(epoch)\n",
    "usage_cpu_percent_rabbit = \"SELECT mean(usage_percent) FROM docker_container_cpu WHERE container_name=~/^rabbit/ and time>='%s' AND time<='%s' GROUP BY container_name, time({}s)\".format(epoch)\n",
    "\n",
    "# rpc-server metric\n",
    "usage_mem_ombt_servers = \"SELECT mean(usage) FROM docker_container_mem WHERE container_name=~/^rpc-server/ and time>='%s' AND time<='%s' GROUP BY container_image, time({}s)\".format(epoch) # container_name\n",
    "usage_cpu_percent_ombt_servers = \"SELECT mean(usage_percent) FROM docker_container_cpu WHERE container_name=~/^rpc-server/ and time>='%s' AND time<='%s' GROUP BY container_image, time({}s)\".format(epoch)\n",
    "\n",
    "usage_mem_ombt_clients = \"SELECT mean(usage) as usage_mem_ombt_clients FROM docker_container_mem WHERE container_name=~/^rpc-client/ and time>='%s' AND time<='%s' GROUP BY container_image, time({}s)\".format(epoch)\n",
    "usage_cpu_percent_ombt_clients = \"SELECT mean(usage_percent) FROM docker_container_cpu WHERE container_name=~/^rpc-client/ and time>='%s' AND time<='%s' GROUP BY container_image, time({}s)\".format(epoch)\n",
    "\n",
    "usage_mem_ombt_controller = \"SELECT mean(usage) FROM docker_container_mem WHERE container_name=~/^controller/ and time>='%s' AND time<='%s' GROUP BY container_image, time({}s)\".format(epoch)\n",
    "usage_cpu_percent_ombt_controller = \"SELECT mean(usage_percent) FROM docker_container_cpu WHERE container_name=~/^controller/ and time>='%s' AND time<='%s' GROUP BY container_image, time({}s)\".format(epoch)\n",
    "\n",
    "# rabbitmq overview serie\n",
    "connections_rabbitmq_overview = \"SELECT mean(connections) from rabbitmq_overview WHERE role='bus' AND time>='%s' AND time<='%s' GROUP BY time({}s)\".format(epoch)\n",
    "\n",
    "# network traffic\n",
    "net_recv_bus = \"SELECT derivative(mean(bytes_recv), 1s)/1048576 FROM net WHERE role='bus' and time>='%s' AND time<='%s' GROUP BY time({}s), host\".format(epoch)\n",
    "net_sent_bus = \"SELECT derivative(mean(bytes_recv), 1s)/1048576 FROM net WHERE role='bus' and time>='%s' AND time<='%s' GROUP BY time({}s), host\".format(epoch)\n",
    "\n",
    "tqdm_params = tqdm_notebook(PARAMS, desc=\"Iterations:\")\n",
    "for param in tqdm_params:    \n",
    "    # get experimentation boundaries\n",
    "    start_time = max(param['_agg_clients']['start_time'], param['_agg_servers']['start_time']) - 30\n",
    "    stop_time = max(param['_agg_clients']['stop_time'], param['_agg_servers']['stop_time']) + 30\n",
    "    duration = stop_time - start_time\n",
    "    start_utc = datetime.utcfromtimestamp(start_time)\n",
    "    stop_utc = datetime.utcfromtimestamp(stop_time)    \n",
    "    #print(\"start=%s, stop=%s\" % (start_utc, stop_utc))\n",
    "    iteration_directory = path.join(RESULT_PATH, param['backup_dir'])\n",
    "    tar = path.join(iteration_directory, 'influxdb-data.tar.gz')\n",
    "    subprocess.check_call(\"tar xfz {}\".format(tar), shell=True)\n",
    "    #tarfile.open(tar).extractall(numeric_owner=True) #path=iteration_directory)\n",
    "    # docker run --name influxdb -v $(pwd)/influxdb-data:/var/lib/influxdb -p 8083:8083 -p 8086:8086 -ti influxdb\n",
    "    # Evaluate the \"load\" of ombt-server/bus :\n",
    "    # we take the min of the usage_idle of all host in the groups ombt-server/bus\n",
    "    # we take the max of the memory usage of all routers in the groups bus (we assume that the bus containers are eating more than the other containers)\n",
    "    QUERIES = {\n",
    "        \"usage_mem_bus\": usage_mem_bus % (start_utc, stop_utc),\n",
    "        \"usage_cpu_percent_bus\": usage_cpu_percent_bus % (start_utc, stop_utc),\n",
    "        \"tcp_established_bus\": tcp_established_bus % (start_utc, stop_utc),\n",
    "        \"usage_mem_rabbit\": usage_mem_rabbit % (start_utc, stop_utc),\n",
    "        \"usage_cpu_percent_rabbit\": usage_cpu_percent_rabbit % (start_utc, stop_utc),\n",
    "        \"usage_mem_ombt_servers\": usage_mem_ombt_servers % (start_utc, stop_utc),\n",
    "        \"usage_cpu_percent_ombt_servers\": usage_cpu_percent_ombt_servers % (start_utc, stop_utc),\n",
    "        \"usage_mem_ombt_clients\": usage_mem_ombt_clients % (start_utc, stop_utc),\n",
    "        \"usage_cpu_percent_ombt_clients\": usage_cpu_percent_ombt_clients % (start_utc, stop_utc),\n",
    "        \"usage_mem_ombt_controller\": usage_mem_ombt_controller % (start_utc, stop_utc),\n",
    "        \"usage_cpu_percent_ombt_controller\": usage_cpu_percent_ombt_controller % (start_utc, stop_utc),\n",
    "        \"connections_rabbitmq_overview\": connections_rabbitmq_overview % (start_utc, stop_utc),\n",
    "        \"net_recv_bus(MB/s)\": net_sent_bus % (start_utc, stop_utc),\n",
    "        \"net_sent_bus(MB/s)\": net_sent_bus % (start_utc, stop_utc),\n",
    "    }\n",
    "\n",
    "    #tqdm_queries = tqdm_notebook(QUERIES.items(), desc=\"Iteration\", bar_format=\"{n}/|/ {desc}: {n_fmt}/{total_fmt}\") \n",
    "    try:\n",
    "        volume_key = path.join(os.getcwd(), 'influxdb-data')\n",
    "        container = client.containers.run('influxdb:latest',\n",
    "                                          name=\"influxdb\",\n",
    "                                          detach=True,\n",
    "                                          ports={'8086/tcp': 8086, \n",
    "                                                 '8083/tcp': 8083},\n",
    "                                          volumes={volume_key: {'bind': '/var/lib/influxdb', \n",
    "                                                                'mode': 'rw'}})        \n",
    "        wait_influx_to_get_ready(debug=False)\n",
    "        influx = DataFrameClient(database=database, timeout=600)       \n",
    "        for key, query in QUERIES.items(): #tqdm_queries:            \n",
    "            #tqdm_queries.set_description(\"Iteration {}:\".format(tqdm_params.last_print_n + 1))\n",
    "            result = influx.query(query)            \n",
    "            # saving the dataframes\n",
    "            param.setdefault(\"_metrics\", {})           \n",
    "            param[\"_metrics\"][key] = result\n",
    "    except Exception as e:\n",
    "        print(e) \n",
    "    finally:\n",
    "        container.stop()\n",
    "        container.remove(force=True)\n",
    "        subprocess.check_call(\"rm -rf influxdb-data\", shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdate\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from pandas.tseries.converter import (TimeSeries_DateLocator, TimeSeries_DateFormatter)\n",
    "\n",
    "\n",
    "def draw_metrics(metric, params, title=\"\"):\n",
    "    # hold the plot/legends of the same key \n",
    "    # e.g (router0: ax, router1: ax)\n",
    "    axs = {}\n",
    "    legends = {}    \n",
    "    for param in sorted(params, key=operator.itemgetter(\"_ombt_servers\")):    \n",
    "        dfs = param[\"_metrics\"][metric]\n",
    "        keys = dfs.keys() \n",
    "        \n",
    "        for key in keys:\n",
    "            # shift\n",
    "            df = dfs[key]            \n",
    "            v = df.index.values - df.index.values[0]            \n",
    "            df['shifted'] = pd.Series(v, index=df.index)\n",
    "            \n",
    "            axs.setdefault(key, None)            \n",
    "            axs[key] = df.plot(x=\"shifted\", ax=axs[key], rot=30)      \n",
    "            #axs[key].xaxis.set_major_formatter(TimeSeries_DateFormatter(df['shifted']))\n",
    "            #print(type(axs[key]))\n",
    "            #print(axs[key].get_xticks())\n",
    "            #print(len(axs[key].get_xticks()))\n",
    "            #print(type(axs[key].get_xticks()))\n",
    "            \n",
    "            # TODO add the key somewhere to differentiate between agent of the bus\n",
    "            # e.g router0, router1, ...\n",
    "            legends.setdefault(key, [])\n",
    "            legends[key].append(\"%s, %s\" % (param[\"_ombt_clients\"], param[\"_ombt_servers\"]))    \n",
    "    for key, ax in axs.items():        \n",
    "        if ax:            \n",
    "            ax.set_xlabel(\"Time\")            \n",
    "            ax.set_title(\"%s \\n %s \\n %s\" % (metric, key, title))\n",
    "            ax.legend(legends[key], bbox_to_anchor=(1, 0.5), loc=\"center left\")       \n",
    "            ax.xaxis.set_major_locator(ticker.MaxNLocator(10))\n",
    "            #ax.xaxis.set_minor_locator(ticker.MaxNLocator(len(axs.items())*10))\n",
    "            #delta = pd.Timedelta(0, unit='s')\n",
    "            #print(ax.get_xticklabels())\n",
    "            #print(ax.xaxis.get_minor_locator())\n",
    "            #majlocator = TimeSeries_DateLocator(\"S\", plot_obj=ax)\n",
    "            #ax.xaxis.set_minor_locator(majlocator)\n",
    "            #ax.set_xticklabels(xxx.index)\n",
    "            \n",
    "            #date_fmt = '%M:%S'           \n",
    "            #date_formatter = mdate.DateFormatter(date_fmt)\n",
    "            #ax.xaxis.set_major_formatter(date_formatter)\n",
    "                \n",
    "        \n",
    "def draw_metrics_versus_iteration(data, drivers, metric, call_type):        \n",
    "    for driver in drivers:\n",
    "        params = [p for p in data if p[\"call_type\"] == call_type and p[\"driver\"] == driver]\n",
    "        draw_metrics(metric, params, title=\"%s - %s\" % (driver, call_type))\n",
    " \n",
    "# For each client there will one line per number of servers in the test\n",
    "# plus one axe per group (e.g router1, router2 ...)\n",
    "\n",
    "#PPARAMS = sorted(PARAMS, key=operator.itemgetter('driver', 'call_type', 'nbr_clients'))\n",
    "#groups = [list(g) for _, g in itertools.groupby(PPARAMS, lambda x: x['driver'])]\n",
    "#clients = [list(itertools.accumulate(iteration['nbr_clients'] for iteration in g)) for g in groups]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RPC-CALLs metrics\n",
    "\n",
    "### Memory usage on the bus (qdr)¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers,\"usage_mem_bus\", \"rpc-call\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU usage on the bus (qdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers,\"usage_cpu_percent_bus\", \"rpc-call\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TCP connections established on the bus node (qdr or rabbit)¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers, \"tcp_established_bus\", \"rpc-call\")\n",
    "draw_metrics_versus_iteration(PARAMS, drivers, \"connections_rabbitmq_overview\", \"rpc-call\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network traffic on the bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers, \"net_recv_bus(MB/s)\", \"rpc-call\")\n",
    "draw_metrics_versus_iteration(PARAMS, drivers, \"net_sent_bus(MB/s)\", \"rpc-call\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory usage on the bus (rabbit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers, \"usage_mem_rabbit\", \"rpc-call\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU usage on the bus (rabbit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers, \"usage_cpu_percent_rabbit\", \"rpc-call\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Memory usage of the ombt_servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers, \"usage_mem_ombt_servers\", \"rpc-call\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU usage of the ombt_servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers, \"usage_cpu_percent_ombt_servers\", \"rpc-call\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory usage of the ombt_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers, \"usage_mem_ombt_clients\", \"rpc-call\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU usage of the ombt clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers, \"usage_cpu_percent_ombt_clients\", \"rpc-call\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory usage of the ombt_controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers, \"usage_mem_ombt_controller\", \"rpc-call\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU usage of the ombt controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers, \"usage_cpu_percent_ombt_controller\", \"rpc-call\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RPC-CASTs metrics\n",
    "\n",
    "### Memory usage on the bus (qdr)¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers,\"usage_mem_bus\", \"rpc-cast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU usage on the bus (qdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers,\"usage_cpu_percent_bus\", \"rpc-cast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TCP connections established on the bus node (qdr or rabbit)¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers, \"tcp_established_bus\", \"rpc-cast\")\n",
    "draw_metrics_versus_iteration(PARAMS, drivers, \"connections_rabbitmq_overview\", \"rpc-cast\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network traffic on the bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers, \"net_recv_bus(MB/s)\", \"rpc-cast\")\n",
    "draw_metrics_versus_iteration(PARAMS, drivers, \"net_sent_bus(MB/s)\", \"rpc-cast\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory usage on the bus (rabbit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers, \"usage_mem_rabbit\", \"rpc-cast\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU usage on the bus (rabbit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers, \"usage_cpu_percent_rabbit\", \"rpc-cast\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Memory usage of the ombt_servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers, \"usage_mem_ombt_servers\", \"rpc-cast\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU usage of the ombt_servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers, \"usage_cpu_percent_ombt_servers\", \"rpc-cast\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory usage of the ombt_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers, \"usage_mem_ombt_clients\", \"rpc-cast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU usage of the ombt clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers, \"usage_cpu_percent_ombt_clients\", \"rpc-cast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory usage of the ombt_controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers, \"usage_mem_ombt_controller\", \"rpc-cast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU usage of the ombt controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_versus_iteration(PARAMS, drivers, \"usage_cpu_percent_ombt_controller\", \"rpc-cast\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
